{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://mermaid.ink/img/pako:eNp9V9tu4zYQ_RVWTy3gGI5zN4o8tNlegO6m2EWBoDBA0NLI4q5EqiTlrBPk3ztDyhapKDECR5pDzo1nZujnLNcFZKssr4W1d1JsjWjWiuHHS9jfsoVaKngOQsaUaGDFrDMHQYMKau72bSpu-41cd67tHG-Fq1aMvtfqsKazYLhUCK-CuaNO0bZgRsJCODES6QqN3iv4Q7sPiiIxrNSGuQpYLhxstZG5qP1OctAOpttaO_JXG7BM1LXfQ0LLZMn2umOPQjnmNLNiB4Q27FG6yq_Tm6-Quxnb7FkBpehqx6Bp3f6gHHaiXvnvTjipVZ9LXQYrYNDJRqgcNSnmwKIqZ4RUTKiC4S5ZhG3ktwU3eM3YppN1wRthHabu82-__vjTgA0GE-l3XKpEzQfFMVyCcJ0BLpuWb4ShFMQwvfNcGwO132pj0Oiciy7nFAL3EcQoJY4f-PMmwDFmNNBseqLYVyspKrAcc-bX4Z6Cj90cL5yO1VaiRXui3luZ2PG-S7WNZVMqai2KKCS2zkiCBAoaoDjS3h-lAUytssxCXa6zoOQl_FPagefqQRvqIjav1-obQMuQDI1EFa4SyMJKIi0tK6VzaINIgzx6CCnHHQeizA7crYizcQXshJFiU4OdBY3CAO3rlPyvg3qPJGmxECwql0F5xEJv_VFijWwwLNYajYqaHw4BTUXykXqCperJK60t4kY3DOk6Yw-__zJjCjqjFdZfC4UsybzIyam8kg7yigjpE9hgebIQoo_VM23uO4492A-1NbSS56hY9rhZOomxPOHphurrvZz5N9rG_DbKLx0mpoAs-85wzEawIfDPOSM3nQM7WKHP3f2fqeDzP5_4x_u7D399SeWiKPgGVF41wnxLoVzX3HYbX_AjOTJ6a3TXWo6t6h10JzXGli4gbvDQd2Mxnrg2jiMK9CVStJTbiT3YI2jPW46GSfB627SEh2xzosYINZr6ayrE0-hyINtdo0bZN_px0qFBjsbUdgR2CrWpEpspnmk-PlGCo974Ggy59p0oBac8ccJsX8moa-a6wpSOgL4bpdKdtB128XBuLGkmgZ5haEb0H003wlGr9cWKZVeCARxxgTqe9J5LFkddnIyYYNNSbrabN5CYkC-HORbcJdJFzj5Ejxw7IS_KsQQDiEXYohKr_VFbrls_qRIQSdO7FOtNgJSmPdG409xAo3cwCeFRKYuJHMBC5o6_RVZvifZht6WF0SgNO2LnhpY2yPbRY5qAp-gxIIMAz_Zrh2TDvsMf_MDFVMazzs-11Olkzk8io_P0l6foQMONMI2SqNhfsvCyMwL9ReuIVkCtv6TxQo3XAnJb0PQrZQ0T7KfLz_PktSZyCSsufQsj1B_H6DaQXATiZGId8waoZSQ5InG7e-8qFN37-otMcrtIounvQs_r6drBOx0P8UZweDxO4Z9PTl5RKLSI96D5_KhhpO_k5JYNgyI2c-uTH-T05Jf2EUwoOSIjbD6_DcefzbIGMFGywB8m_kzXGV3AYZ2t8LGgyYnD_wXXic7pL3uVZytnOphlWF_b6vDStTTd-h81ByHWHbbFj_2vHuz_cot6WqGy1XP2PVudnC4v52fLs8VycbNYXp9fLq5n2T5bLS-X88XFzenl8uLsfHm1vDp7mWVPWqPi0_nZ1fXV9enN6fnV6eLm5vrCK_zXg6WoLbz8D4O3OsQ?type=png)](https://mermaid.live/edit#pako:eNp9V9tu4zYQ_RVWTy3gGI5zN4o8tNlegO6m2EWBoDBA0NLI4q5EqiTlrBPk3ztDyhapKDECR5pDzo1nZujnLNcFZKssr4W1d1JsjWjWiuHHS9jfsoVaKngOQsaUaGDFrDMHQYMKau72bSpu-41cd67tHG-Fq1aMvtfqsKazYLhUCK-CuaNO0bZgRsJCODES6QqN3iv4Q7sPiiIxrNSGuQpYLhxstZG5qP1OctAOpttaO_JXG7BM1LXfQ0LLZMn2umOPQjnmNLNiB4Q27FG6yq_Tm6-Quxnb7FkBpehqx6Bp3f6gHHaiXvnvTjipVZ9LXQYrYNDJRqgcNSnmwKIqZ4RUTKiC4S5ZhG3ktwU3eM3YppN1wRthHabu82-__vjTgA0GE-l3XKpEzQfFMVyCcJ0BLpuWb4ShFMQwvfNcGwO132pj0Oiciy7nFAL3EcQoJY4f-PMmwDFmNNBseqLYVyspKrAcc-bX4Z6Cj90cL5yO1VaiRXui3luZ2PG-S7WNZVMqai2KKCS2zkiCBAoaoDjS3h-lAUytssxCXa6zoOQl_FPagefqQRvqIjav1-obQMuQDI1EFa4SyMJKIi0tK6VzaINIgzx6CCnHHQeizA7crYizcQXshJFiU4OdBY3CAO3rlPyvg3qPJGmxECwql0F5xEJv_VFijWwwLNYajYqaHw4BTUXykXqCperJK60t4kY3DOk6Yw-__zJjCjqjFdZfC4UsybzIyam8kg7yigjpE9hgebIQoo_VM23uO4492A-1NbSS56hY9rhZOomxPOHphurrvZz5N9rG_DbKLx0mpoAs-85wzEawIfDPOSM3nQM7WKHP3f2fqeDzP5_4x_u7D399SeWiKPgGVF41wnxLoVzX3HYbX_AjOTJ6a3TXWo6t6h10JzXGli4gbvDQd2Mxnrg2jiMK9CVStJTbiT3YI2jPW46GSfB627SEh2xzosYINZr6ayrE0-hyINtdo0bZN_px0qFBjsbUdgR2CrWpEpspnmk-PlGCo974Ggy59p0oBac8ccJsX8moa-a6wpSOgL4bpdKdtB128XBuLGkmgZ5haEb0H003wlGr9cWKZVeCARxxgTqe9J5LFkddnIyYYNNSbrabN5CYkC-HORbcJdJFzj5Ejxw7IS_KsQQDiEXYohKr_VFbrls_qRIQSdO7FOtNgJSmPdG409xAo3cwCeFRKYuJHMBC5o6_RVZvifZht6WF0SgNO2LnhpY2yPbRY5qAp-gxIIMAz_Zrh2TDvsMf_MDFVMazzs-11Olkzk8io_P0l6foQMONMI2SqNhfsvCyMwL9ReuIVkCtv6TxQo3XAnJb0PQrZQ0T7KfLz_PktSZyCSsufQsj1B_H6DaQXATiZGId8waoZSQ5InG7e-8qFN37-otMcrtIounvQs_r6drBOx0P8UZweDxO4Z9PTl5RKLSI96D5_KhhpO_k5JYNgyI2c-uTH-T05Jf2EUwoOSIjbD6_DcefzbIGMFGywB8m_kzXGV3AYZ2t8LGgyYnD_wXXic7pL3uVZytnOphlWF_b6vDStTTd-h81ByHWHbbFj_2vHuz_cot6WqGy1XP2PVudnC4v52fLs8VycbNYXp9fLq5n2T5bLS-X88XFzenl8uLsfHm1vDp7mWVPWqPi0_nZ1fXV9enN6fnV6eLm5vrCK_zXg6WoLbz8D4O3OsQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, packages, loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup pipeline package w/o loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import * #Load our package with classes pipeline, models, pp (preprocessing), plot, and more\n",
    "path= userpath(os.environ.get(\"USER\", os.environ.get(\"USERNAME\")), project=\"hcc\") # Choose your own project here, only works if you added specific project in user_settings.json\n",
    "pd.options.display.max_rows=100\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preexisting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import * #Load our package with classes pipeline, models, pp (preprocessing), plot, and more\n",
    "path= userpath(os.environ.get(\"USER\", os.environ.get(\"USERNAME\")), project=\"hcc\") # Choose your own project here, only works if you added specific project in user_settings.json\n",
    "pl=load_Pipeline(path + \"/Models/Pipelines/RFC/Pipeline_HCC_all_Model_C_RFC.joblib\") #Change for pipeline you want\n",
    "\n",
    "pl.mapper.color_groups ={\"df_covariates\": '#4995AD', \"df_diagnosis\": '#385579', \"df_blood\": '#C13B2E', \"df_snp\": '#F0A551', \"df_metabolomics\": '#F0D79A'}\n",
    "pl.mapper.color_groups_violin= {'Model_A': (0.28627450980392155, 0.5843137254901961, 0.6784313725490196),\n",
    "    'Model_B': (0.2196078431372549, 0.3333333333333333, 0.4745098039215686),\n",
    "    'Model_C': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    "    'Model_Csmall': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    "    'Model_D': (0.9411764705882353, 0.5647058823529412, 0.24313725490196078),\n",
    "    'Model_E': (0.9411764705882353, 0.7843137254901961, 0.4470588235294118),\n",
    "    'Model_TOP75': (0.796078431372549, 0.4, 0.29411764705882354),\n",
    "    'Model_TOP30': (0.807843137254902, 0.5647058823529412, 0.4980392156862745),\n",
    "    'Model_TOP15': (0.7803921568627451, 0.7215686274509804, 0.7058823529411765)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.only_val = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.master_RFC.predict_proba(pl.ohe.transform(pl.data.X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.ohe.transform(pl.data.X_val, sparse_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop  for import/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chosen_subset in [\"all\", \"par\"]:\n",
    "    for chosen_model in [\"Model_C\", \"Model_TOP15\"]:   #\n",
    "        pl = {}\n",
    "        user_input={}\n",
    "        #Set metadata of prediction model\n",
    "        ##################################################################################################################################\n",
    "        user_input[\"export_date_data\"]=\"09_09_2024\"\n",
    "        user_input[\"DOI\"] = \"HCC\"\n",
    "        user_input[\"row_subset\"] = chosen_subset  # \"par\" or \"all\" or \"par_Cirrhosis\"\n",
    "        user_input[\"col_subset\"] = chosen_model\n",
    "        pl=load_Pipeline(path + f\"/Models/Pipelines/RFC/Pipeline_HCC_{chosen_subset}_{chosen_model}_RFC.joblib\") #Change for pipeline you want\n",
    "        pl.evaluation_summary_threshold_dependent(thresholds=np.arange(0.7, 0.29, -0.02), beta=10)\n",
    "        pl.evaluation_summary_threshold_independent() #AUROCS and AUPRCS\n",
    "        #pl.save_Pipeline_and_comb_outputs()\n",
    "        #ext_val=export_ext_val(pl)\n",
    "        #ext_val.save_to('.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Ext.val export object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class for ext_val (creation and export)\n",
    "class export_ext_val:\n",
    "    def __init__(self,pl) -> None:\n",
    "        self.user_input=pl.user_input\n",
    "        self.master_RFC=pl.master_RFC\n",
    "        self.list_estimators=[i.best_estimator_ for i in pl.master_RFC.models]\n",
    "        self.name=pl.name\n",
    "        self.ohe=pl.ohe\n",
    "        self.mapper=pl.mapper\n",
    "        self.columngroups_df=pl.data.columngroups_df\n",
    "        self.pipeline_output_path='.'# setzt den export path auf das dir in dem wir uns befinden !!!! adjust if needed on external server to the folder you want\n",
    "        ## export the trained_model class partly:\n",
    "        for key, value_orig in pl.trained_model.model_with_info.items():\n",
    "            value_new = {\"model\": value_orig.get(\"model\")}\n",
    "            value_orig.clear()\n",
    "            value_orig.update(value_new)\n",
    "        self.trained_model = pl.trained_model\n",
    "    def save_to(self,path:str ='.'):\n",
    "        save_dir = os.path.join(self.user_input.path, \"Models\", \"Validation_Objects\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        file_path = os.path.join(save_dir, f\"{self.name}_external_val.joblib\")\n",
    "        dump(self, file_path)\n",
    "\n",
    "            # Print confirmation message\n",
    "        print(f\"External validation object has been saved to: {os.path.abspath(file_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for external validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class for ext_val (creation and export)\n",
    "class export_ext_val:\n",
    "    def __init__(self,pl) -> None:\n",
    "        self.user_input=pl.user_input\n",
    "        self.master_RFC=pl.master_RFC\n",
    "        self.list_estimators=[i.best_estimator_ for i in pl.master_RFC.models]\n",
    "        self.name=pl.name\n",
    "        self.ohe=pl.ohe\n",
    "        self.mapper=pl.mapper\n",
    "        self.columngroups_df=pl.data.columngroups_df\n",
    "        self.pipeline_output_path='.'# setzt den export path auf das dir in dem wir uns befinden !!!! adjust if needed on external server to the folder you want\n",
    "        ## export the trained_model class partly:\n",
    "        for key, value_orig in pl.trained_model.model_with_info.items():\n",
    "            value_new = {\"model\": value_orig.get(\"model\")}\n",
    "            value_orig.clear()\n",
    "            value_orig.update(value_new)\n",
    "        self.trained_model = pl.trained_model\n",
    "    def save_to(self,path:str ='.'):\n",
    "        save_dir = os.path.join(self.user_input.path, \"Models\", \"Validation_Objects\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        file_path = os.path.join(save_dir, f\"{self.name}_external_val.joblib\")\n",
    "        dump(self, file_path)\n",
    "\n",
    "            # Print confirmation message\n",
    "        print(f\"External validation object has been saved to: {os.path.abspath(file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and export ext_val class\n",
    "ext_val=export_ext_val(pl)\n",
    "ext_val.save_to('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import for external validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_val = load(\"C:/Users/janni/Uniklinik RWTH Aachen/CRC-1382-A11 - public/projects/hcc/Models/Validation_Objects/Pipeline_HCC_all_Model_TOP15_RFC_external_val.joblib\")\n",
    "pl_ext=Pipeline(ext_val_obj=ext_val)\n",
    "pl_ext.columngroups_df\n",
    "pl_ext.external_validation(X_val=pl.data.X_val,y_val=pl.data.y_val)\n",
    "pl_ext.ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new user input (for new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input={}\n",
    "#Set metadata of prediction model\n",
    "##################################################################################################################################\n",
    "user_input[\"export_date_data\"]=\"09_09_2024\"\n",
    "user_input[\"DOI\"] = \"HCC\"\n",
    "user_input[\"project\"] = \"hcc\"\n",
    "user_input[\"row_subset\"] = \"par\"  # \"par\" or \"all\" or \"par_Cirrhosis\"\n",
    "user_input[\"col_subset\"]= \"Model_A\" # ->Change this line to select another model combination\n",
    "user_input[\"test_cohort\"] = \"val\" #applying model to either \"test\" or \"val\" data\n",
    "user_input[\"visual_export\"] = True #Decide whether you just want to play around or export your visuals\n",
    "user_input[\"run_conf_matrices\"]=True\n",
    "user_input[\"run_violin_plot\"]=True\n",
    "user_input[\"run_feature_imp\"] = True\n",
    "user_input[\"RUN_MODELS\"] = True  # True Or False, Set on False if just evaluating\n",
    "user_input[\"add_benchmark\"] = True\n",
    "user_input[\"path\"] = path\n",
    "user_input[\"target\"] = \"status\" #status, #status_cancerreg or whatever you want to call the relevant column\n",
    "user_input[\"target_to_validate_on\"] = \"status_cancerreg\"\n",
    "\n",
    "# define a color scheme:\n",
    "user_input[\"color_groups_all\"]={\"df_covariates\": '#4995AD', \"df_diagnosis\": '#385579', \"df_blood\": '#C13617', \"df_snp\": '#F0903E', \"df_metabolomics\": '#F0C872', \"TOP75\": '#cb664b',\n",
    "        \"TOP30\": '#ce907f', \"TOP15\": '#c7b8b4'}\n",
    "user_input[\"color_groups_violin\"]={'Model_A': (0.28627450980392155, 0.5843137254901961, 0.6784313725490196),\n",
    " 'Model_B': (0.2196078431372549, 0.3333333333333333, 0.4745098039215686),\n",
    " 'Model_C': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    " 'Model_Csmall': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    " 'Model_AMAP-RFC': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    " 'Model_D': (0.9411764705882353, 0.5647058823529412, 0.24313725490196078),\n",
    " 'Model_E': (0.9411764705882353, 0.7843137254901961, 0.4470588235294118),\n",
    " 'Model_TOP75': (0.796078431372549, 0.4, 0.29411764705882354),\n",
    " 'Model_TOP30': (0.807843137254902, 0.5647058823529412, 0.4980392156862745),\n",
    " 'Model_TOP15': (0.7803921568627451, 0.7215686274509804, 0.7058823529411765)}\n",
    "\n",
    "user_input['training']={\"random_state\":1, # set random state to eval. variance in analysis?\n",
    "    \"cross_validation_method\":\"grouped\",#\"stratified\" or \"grouped\"\n",
    "    \"n_splits\":5,\n",
    "    \"n_jobs_indiv\":8,  # choose depending on your machine...\n",
    "    # adjust for the different models\n",
    "    \"hyper_para_options\":{\n",
    "\n",
    "    ####### RFC\n",
    "    #'ccp_alpha': 0.0,\n",
    "    #'class_weight': 'balanced_subsample',\n",
    "    #'criterion': 'gini', -> options???\n",
    "    'max_depth':[3],\n",
    "    #'max_features': 'sqrt',\n",
    "    #'max_leaf_nodes': None,\n",
    "    #'max_samples': None,\n",
    "    #'min_impurity_decrease': 0.0,\n",
    "    #'min_samples_leaf': 1,\n",
    "    #'min_samples_split': [2,3,4,5],\n",
    "    #'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators':[50],\n",
    "    #'n_jobs': 2,\n",
    "    #'oob_score': False,\n",
    "    #'random_state':np.random.randint(low=0,high=100,size=n_splits).tolist(), #### iterate here\n",
    "    #'verbose': [1],\n",
    "\n",
    "    ######## NN:\n",
    "    },\n",
    "    \"scoring_grid_search\":\"balanced_accuracy\",#'roc_auc_ovo_weighted', #'balanced_accuracy', 'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted','f1_weighted', #sklearn.metrics.get_scorer_names()\n",
    "    'verbose':1,\n",
    "}\n",
    "##################################################################################################################################\n",
    "\n",
    "#Further user input is generated automatically :) check out pl.user_input.fig_path and more :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Pipeline, training, models and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl=Pipeline(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.training('RFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.build_master_RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl=Pipeline(user_input)\n",
    "pl.training('RFC')\n",
    "pl.build_master_RFC()\n",
    "pl.master_RFC.get_best_params()\n",
    "pl.evaluation()\n",
    "pl.save_Pipeline_and_comb_outputs()\n",
    "ext_val=export_ext_val(pl)\n",
    "ext_val.save_to('.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chosen_subset in [\"par\"]:\n",
    "    #for chosen_model in [\"Model_A\", \"Model_B\", \"Model_C\", \"Model_D\", 'Model_E']:   #danach par Model SNP, Model Metabolomics\n",
    "    #for chosen_model in [\"Model_Demographics\", \"Model_Diagnosis\", \"Model_Blood\", \"Model_SNP\", \"Model_Metabolomics\"]:\n",
    "    #for chosen_model in [\"Model_TOP75\", 'Model_TOP30', 'Model_TOP15', \"Model_AMAP-RFC\"]:\n",
    "    for chosen_model in [\"Model_TOP75\", 'Model_TOP30', 'Model_TOP15', \"Model_AMAP-RFC\"]:   #danach par Model SNP, Model Metabolomics\n",
    "        user_input={}\n",
    "        #Set metadata of prediction model\n",
    "        ##################################################################################################################################\n",
    "        user_input[\"export_date_data\"]=\"09_09_2024\"\n",
    "        user_input[\"DOI\"] = \"HCC\"\n",
    "        user_input[\"project\"] = \"hcc\"\n",
    "        user_input[\"row_subset\"] = chosen_subset  # \"par\" or \"all\" or \"par_Cirrhosis\"\n",
    "        user_input[\"col_subset\"] = chosen_model\n",
    "        user_input[\"test_cohort\"] = \"val\" #applying model to either \"test\" or \"val\" data\n",
    "        user_input[\"visual_export\"] = True #Decide whether you just want to play around or export your visuals\n",
    "        user_input[\"run_conf_matrices\"]=True\n",
    "        user_input[\"run_violin_plot\"]=True\n",
    "        user_input[\"run_feature_imp\"] = True\n",
    "        user_input[\"RUN_MODELS\"] = True  # True Or False, Set on False if just evaluating\n",
    "        user_input[\"add_benchmark\"] = True\n",
    "        user_input[\"target\"] = \"status\" #status, #status_cancerreg or whatever you want to call the relevant column\n",
    "        user_input[\"target_to_validate_on\"] = \"status_cancerreg\"\n",
    "\n",
    "        # define a color scheme:\n",
    "        user_input[\"color_groups_all\"]={\"df_covariates\": '#4995AD', \"df_diagnosis\": '#385579', \"df_blood\": '#C13617', \"df_snp\": '#F0903E', \"df_metabolomics\": '#F0C872', \"TOP75\": '#cb664b',\n",
    "                \"TOP30\": '#ce907f', \"TOP15\": '#c7b8b4'}\n",
    "        user_input[\"color_groups_violin\"]={'Model_A': (0.28627450980392155, 0.5843137254901961, 0.6784313725490196),\n",
    "        'Model_B': (0.2196078431372549, 0.3333333333333333, 0.4745098039215686),\n",
    "        'Model_C': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    "        'Model_Csmall': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    "        'Model_AMAP-RFC': (0.7568627450980392, 0.21176470588235294, 0.09019607843137255),\n",
    "        'Model_D': (0.9411764705882353, 0.5647058823529412, 0.24313725490196078),\n",
    "        'Model_E': (0.9411764705882353, 0.7843137254901961, 0.4470588235294118),\n",
    "        'Model_TOP75': (0.796078431372549, 0.4, 0.29411764705882354),\n",
    "        'Model_TOP30': (0.807843137254902, 0.5647058823529412, 0.4980392156862745),\n",
    "        'Model_TOP15': (0.7803921568627451, 0.7215686274509804, 0.7058823529411765)}\n",
    "\n",
    "        user_input['training']={\"random_state\":1, # set random state to eval. variance in analysis?\n",
    "            \"cross_validation_method\":\"grouped\", #\"stratified\" or \"grouped\"\n",
    "            \"n_splits\":5,\n",
    "            \"n_jobs_indiv\":8,  # choose depending on your machine...\n",
    "            # adjust for the different models\n",
    "            \"hyper_para_options\":{\n",
    "            #'ccp_alpha': 0.0,\n",
    "            #'class_weight': 'balanced_subsample',\n",
    "            #'criterion': 'gini', -> options???\n",
    "            'max_depth':[3],\n",
    "            #'max_features': 'sqrt',\n",
    "            #'max_leaf_nodes': None,\n",
    "            #'max_samples': None,\n",
    "            #'min_impurity_decrease': 0.0,\n",
    "            #'min_samples_leaf': 1,\n",
    "            #'min_samples_split': [2,3,4,5],\n",
    "            #'min_weight_fraction_leaf': 0.0,\n",
    "            'n_estimators':[50],\n",
    "            #'n_jobs': 2,\n",
    "            #'oob_score': False,\n",
    "            #'random_state':np.random.randint(low=0,high=100,size=n_splits).tolist(), #### iterate here\n",
    "            #'verbose': [1],\n",
    "            },\n",
    "            \"scoring_grid_search\":\"balanced_accuracy\",#'roc_auc_ovo_weighted', #'balanced_accuracy', 'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted','f1_weighted', #sklearn.metrics.get_scorer_names()\n",
    "            'verbose':1,\n",
    "        }\n",
    "\n",
    "        pl=Pipeline(user_input)\n",
    "\n",
    "        pl.training('RFC')\n",
    "        pl.build_master_RFC()\n",
    "        pl.master_RFC.get_best_params()\n",
    "        pl.evaluation()\n",
    "        pl.save_Pipeline_and_comb_outputs(only_val=True)\n",
    "        #ext_val=export_ext_val(pl)\n",
    "        #ext_val.save_to('.')\n",
    "\n",
    "        # Threshold independent metrics (AUCs, AUPRCs, both per model and for the average)\n",
    "        pl.evaluation_summary_independent()\n",
    "        #Threshold-dependent metrics ('Precision, Recall, Accuracy, F1 Score, F-beta, Balanced accuracy, PPV, NPV\n",
    "        pl.evaluation_summary_threshold_dependent(thresholds=np.arange(0.7, 0.29, -0.02), beta=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.evaluation()\n",
    "pl.save_Pipeline_and_comb_outputs()\n",
    "ext_val=export_ext_val(pl)\n",
    "ext_val.save_to('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.build_master_RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.master_RFC.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.z_val.status_cancerreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.save_Pipeline_and_comb_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcut to load new model instance\n",
    "from pipeline import * #Load our package with classes pipeline, models, pp (preprocessing), plot, and more\n",
    "path= userpath(os.environ.get(\"USER\", os.environ.get(\"USERNAME\")), project=\"hcc\") # Choose your own project here, only works if you added specific project in user_settings.json\n",
    "pl=load_Pipeline(path + \"/Models/Pipelines/RFC/Pipeline_HCC_all_Model_C_RFC.joblib\") #Change for pipeline you want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\").status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export pred values\n",
    "\n",
    "val_df = pl.eval.test_train_pred.get(\"val\")\n",
    "\n",
    "# Create a copy to avoid modifying the original data\n",
    "df_shuffled = val_df.copy()\n",
    "\n",
    "# Randomly shuffle the rows\n",
    "df_shuffled = df_shuffled.sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "# Remove specified columns\n",
    "columns_to_remove = [\"date_of_diag\", \"assessment\", \"difftime\"]\n",
    "df_shuffled = df_shuffled.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Reset the index and drop the old index column if it exists\n",
    "df_shuffled = df_shuffled.reset_index(drop=True)\n",
    "\n",
    "# Display info about the new DataFrame\n",
    "print(df_shuffled.info())\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "print(df_shuffled.head())\n",
    "\n",
    "\n",
    "df_shuffled.to_csv(f\"{pl.user_input.path}/data/pred_values_top15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.roc_auc_test_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.eval.test_train_pred.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.create_violin_plot(pl, data=pl.eval.test_train_pred.get(\"val\"), model=pl.master_RFC,ohe=pl.ohe, truth=\"status_cancerreg\", gap=-0.1, width=0.8, thresholds_choice=[0,.35,.55,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump violin object to joblib for the Web-tool\n",
    "import joblib\n",
    "fig, ax= plot.create_violin_plot(pl, data=pl.eval.test_train_pred.get(\"val\"), model=pl.master_RFC,ohe=pl.ohe, truth=\"status_cancerreg\", gap=-0.1, width=0.8, thresholds_choice=[0,.35,.55,1])\n",
    "\n",
    "joblib.dump(fig, f'{pl.user_input.fig_path}/violin_top15_app.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.feature_imp_barplot(n_features=50, func_for_aggregation=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.shap_analysis(sample_size=10000, max_display=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save_colorbar(pip_self=pl, figsize=(0.5, 6), font_size=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conf Whole population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All\n",
    "plot.wrapper_eval_prediction_mono(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"],model=pl.master_RFC,thresholds=[0.45, 0.55, 0.35, 0.5, 0.4, 0.3],figsize=(15,10), font_size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All\n",
    "plot.wrapper_eval_prediction_multi(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"],model=pl.master_RFC,thresholds=[(0.5, 0.7), (0.4, 0.6), (0.35, 0.55)],incorp_threh_in_y_label=True,figsize=(13,5), n_rows=1, font_size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.X[\"random\"] = pl.data.X[\"SEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.X[\"random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(pl.ohe.transform(pl.data.X)==pl.ohe.transform(pl.data.X.drop(columns=['random']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conf Stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Males 6x\n",
    "plot.wrapper_eval_prediction_multi(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"],model=pl.master_RFC,thresholds=[(0.4, 0.6), (0.35, 0.55)],incorp_threh_in_y_label=True,figsize=(13,5), n_rows=1, font_size=22, stratify={'column': 'SEX', 'value': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Females 6x\n",
    "plot.wrapper_eval_prediction_multi(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"],model=pl.master_RFC,thresholds=[(0.4, 0.6), (0.35, 0.55)],incorp_threh_in_y_label=True,figsize=(13,5), n_rows=1, font_size=22, stratify={'column': 'SEX', 'value': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Males 4x\n",
    "plot.wrapper_eval_prediction_mono(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"], model=pl.master_RFC,thresholds=[0.45, 0.55, 0.35, 0.5, 0.4, 0.3],\n",
    "    figsize=(15,10), font_size=22, stratify={'column': 'SEX', 'value': 1}  # For males\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Females 4x\n",
    "plot.wrapper_eval_prediction_mono(pip_self=pl,X=pl.data.X_val,y_true=pl.data.z_val[\"status_cancerreg\"], model=pl.master_RFC, thresholds=[0.45, 0.55, 0.35, 0.5, 0.4, 0.3],\n",
    "    figsize=(15,10), font_size=22, stratify={'column': 'SEX', 'value': 0}  # For females\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaplan Meier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_KM(pl,thresholds=(0.35, 0.55),color_dict={'Low Risk':'green','Medium Risk':'yellow','High Risk':'red'}, x_scale=\"y\", y_scale=\"default\", font_size=\"22\"):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def kaplan_meier_analysis(time, event, group, x_scale= x_scale, group_labels=None, plot=True,color_dict=color_dict, font_size=font_size, y_scale=y_scale):\n",
    "        \"\"\"\n",
    "        Perform Kaplan-Meier analysis and compare survival curves between two groups.,\n",
    "        Parameters:,\n",
    "        - time: Array-like object containing the time to event or censoring.,\n",
    "        - event: Array-like object indicating whether an event occurred (1) or not (0).,\n",
    "        - group: Array-like object specifying the group each observation belongs to (e.g., treatmentcontrol).,\n",
    "        - group_labels: List of labels for the two groups (optional).,\n",
    "         -x-scale (y, m, d)\n",
    "        - plot: Boolean indicating whether to plot the survival curves (default is True).,\n",
    "        Returns:,\n",
    "        - kmf: KaplanMeierFitter object containing the survival estimates for each group.,\n",
    "        \"\"\"\n",
    "        # Creating a DataFrame from the provided data,\n",
    "        df = pd.DataFrame({'time': list(time), 'event': list(event), 'group': list(group)})\n",
    "        # Initializing KaplanMeierFitter,\n",
    "        kmf = KaplanMeierFitter()\n",
    "        # Group-wise analysis,\n",
    "        for i, grp in enumerate([i for i in df['group'].unique()]):\n",
    "            data = df.loc[df['group'] == grp,:]\n",
    "            kmf.fit(data['time'], event_observed=data['event'], label=group_labels[i] if group_labels else f'{grp}')\n",
    "            if plot:\n",
    "                kmf.plot(color=color_dict.get(grp,'green'),alpha=0.7)\n",
    "\n",
    "        if plot:\n",
    "            if x_scale == 'y':\n",
    "                plt.xlabel('Time [Years]', fontsize=font_size)\n",
    "            elif x_scale == 'm':\n",
    "                plt.xlabel('Time [Months]', fontsize=font_size)\n",
    "            else:\n",
    "                plt.xlabel('Time [Days]', fontsize=font_size)\n",
    "            plt.ylabel(f'1 - Probability of {pl.user_input.DOI} [%]', fontsize=font_size),\n",
    "            plt.yticks(fontsize=font_size)\n",
    "            plt.xticks(fontsize=font_size)\n",
    "            plt.title(f'Time to {pl.user_input.DOI} per risk group'),\n",
    "            plt.legend(frameon=False, fontsize=font_size, loc=\"lower left\"),\n",
    "            if y_scale != 'default':\n",
    "                plt.ylim(y_scale)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        return kmf\n",
    "\n",
    "    def get_group(pred_prob,thresholds):\n",
    "        groups=[]\n",
    "        for i in pred_prob:\n",
    "            if i <thresholds[0]:\n",
    "                groups.append('Low Risk')\n",
    "            elif i>=thresholds[0] and i<thresholds[1]:\n",
    "                groups.append('Medium Risk')\n",
    "            elif i>=thresholds[1]:\n",
    "                groups.append('High Risk')\n",
    "        return groups\n",
    "\n",
    "    time_censoring=pd.Timestamp(year=2024,day=1,month=1)\n",
    "    time_censoring\n",
    "    z_val=pl.data.z_val\n",
    "\n",
    "\n",
    "    z_val.loc[z_val.date_of_diag.isna(),'date_of_diag']=time_censoring\n",
    "    timedelta=pd.to_datetime(z_val.date_of_diag)-(pd.to_datetime(z_val['Date of assessment']))\n",
    "    z_val['time_to_event_d']= [i.days for i in timedelta]\n",
    "    z_val['time_to_event_m']= z_val['time_to_event_d'] /30\n",
    "    z_val['time_to_event_y']= z_val['time_to_event_d'] /365.25\n",
    "    z_val[\"pred_prob\"]=pl.master_RFC.predict_proba(pl.ohe.transform(pl.data.X_val)).values\n",
    "\n",
    "\n",
    "    z_val['risk_group']=get_group(z_val.pred_prob,thresholds=thresholds)\n",
    "    print('The Thresholds are:',thresholds)\n",
    "    print(z_val.risk_group.value_counts())\n",
    "    fig,ax=plt.subplots(figsize=(10,10))\n",
    "    time_column = f'time_to_event_{x_scale}'\n",
    "    estimator=kaplan_meier_analysis(z_val[time_column], event=z_val.status,group=z_val.risk_group)\n",
    "    estimator.plot_survival_function()\n",
    "\n",
    "    svg_path = os.path.join(pl.user_input.fig_path, f\"KaplanMeier_{pl.user_input.col_subset}_{pl.user_input.row_subset}_{y_scale}.svg\")\n",
    "    fig.savefig(svg_path, format='svg', bbox_inches='tight', transparent=True)\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_KM(pl, thresholds=(0.35, 0.6), x_scale='y', font_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_KM(pl, thresholds=(0.35, 0.55), x_scale='y', y_scale=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Info Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.user_input.col_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.master_RFC.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.data.X_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.save_values_for_combined_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.master_RFC.feature_importances_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create summary tables for model metrics (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import * #Load our package with classes pipeline, models, pp (preprocessing), plot, and more\n",
    "path= userpath(os.environ.get(\"USER\", os.environ.get(\"USERNAME\")), project=\"hcc\") # Choose your own project here, only works if you added specific project in user_settings.json\n",
    "\n",
    "pl=load_Pipeline(path + \"/Models/Pipelines/RFC/Pipeline_HCC_par_Model_C_RFC.joblib\") #Change for pipeline you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold independent metrics (AUCs, AUPRCs, both per model and for the average)\n",
    "pl.evaluation_summary_independent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold-dependent metrics ('Precision, Recall, Accuracy, F1 Score, F-beta, Balanced accuracy, PPV, NPV\n",
    "pl.evaluation_summary_threshold_dependent(thresholds=np.arange(0.7, 0.29, -0.02), beta=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Column names to visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for chosen_subset in [\"all\"]:\n",
    "    for chosen_model in [\"Model_C\", \"Model_TOP75\", \"Model_TOP30\", \"Model_TOP15\", \"Model_AMAP-RFC\"]:   #\n",
    "        user_input={}\n",
    "        #Set metadata of prediction model\n",
    "        ##################################################################################################################################\n",
    "        user_input[\"export_date_data\"]=\"27_05_2024\"\n",
    "        user_input[\"DOI\"] = \"HCC\"\n",
    "        user_input[\"row_subset\"] = chosen_subset  # \"par\" or \"all\" or \"par_Cirrhosis\"\n",
    "        user_input[\"col_subset\"] = chosen_model\n",
    "        pl=load_Pipeline(path + f\"/Models/Pipelines/RFC/Pipeline_HCC_{chosen_subset}_{chosen_model}_RFC.joblib\") #Change for pipeline you want\n",
    "        columns = [col for col in sorted(pl.data.X_val.columns.tolist()) if col not in [\"split_ext\", \"split_int\"]]\n",
    "        data[chosen_model] = columns\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "export_path = pl.user_input.fig_path + \"/output.xlsx\"\n",
    "df.to_excel(export_path, index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model options\n",
    "model_options = ['top75', 'top30', 'top15', 'keep_amap']\n",
    "\n",
    "# Create a dictionary to store feature lists for each model\n",
    "feature_lists = {}\n",
    "\n",
    "\n",
    "# Process each model option\n",
    "for model in model_options:\n",
    "    # Filter features where the model column is 1\n",
    "    features = pl.data.reduce_df[pl.data.reduce_df[model] == 1]['Feature'].tolist()\n",
    "    feature_lists[model] = features\n",
    "\n",
    "# Find the maximum length of feature lists\n",
    "max_length = max(len(features) for features in feature_lists.values())\n",
    "\n",
    "# Create a new dataframe with feature lists\n",
    "df_reduced_models = pd.DataFrame({\n",
    "    model: pd.Series(features + [None] * (max_length - len(features)))\n",
    "    for model, features in feature_lists.items()\n",
    "})\n",
    "\n",
    "print(df_reduced_models.head())\n",
    "df_reduced_models.to_excel(f\"{path}/supplement/Reduced_Model_Features.xlsx\")\n",
    "\n",
    "# new_df.to_csv('feature_lists_by_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_model_mapping(input_df, model_options):\n",
    "    # Ensure the input dataframe has the correct columns\n",
    "    required_columns = ['Feature'] + model_options\n",
    "    if not all(col in input_df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Input dataframe must contain columns: {required_columns}\")\n",
    "\n",
    "    # Create a dictionary to store feature lists for each model\n",
    "    feature_lists = {}\n",
    "\n",
    "    # Process each model option\n",
    "    for model in model_options:\n",
    "        # Filter features where the model column is 1\n",
    "        features = input_df[input_df[model] == 1]['Feature'].tolist()\n",
    "        feature_lists[model] = features\n",
    "\n",
    "    # Find the maximum length of feature lists\n",
    "    max_length = max(len(features) for features in feature_lists.values())\n",
    "\n",
    "    # Create a new dataframe with feature lists\n",
    "    df_reduced_models = pd.DataFrame({\n",
    "        model: pd.Series(features + [np.nan] * (max_length - len(features)))\n",
    "        for model, features in feature_lists.items()\n",
    "    })\n",
    "\n",
    "    return df_reduced_models\n",
    "\n",
    "# Usage\n",
    "model_options = ['top75', 'top30', 'top15', 'keep_amap']\n",
    "\n",
    "# Assuming pl.data.reduce_df is your input dataframe\n",
    "input_df = pl.data.reduce_df\n",
    "\n",
    "df_reduced_models = create_feature_model_mapping(input_df, model_options)\n",
    "\n",
    "print(df_reduced_models.head())\n",
    "df_reduced_models.to_excel(f\"{path}/supplement/Reduced_Model_Features.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_feature_importance_to_excel(pl, n_features='all', output_path=None):\n",
    "    \"\"\"\n",
    "    Export feature importances to an Excel file.\n",
    "\n",
    "    Args:\n",
    "    pl (Pipeline): The pipeline object containing the trained model.\n",
    "    n_features (int or 'all'): Number of top features to include. Default is 'all'.\n",
    "    output_path (str): Path to save the Excel file. If None, saves in the pipeline's figure path.\n",
    "\n",
    "    Returns:\n",
    "    str: Path to the saved Excel file.\n",
    "    \"\"\"\n",
    "    # Get feature importances\n",
    "    feature_imp_all = pl.master_RFC.feature_importances_()\n",
    "    feature_imp = feature_imp_all[\"mean_feature_imp\"]\n",
    "\n",
    "    # Create DataFrame\n",
    "    plot_X = pl.data.X_ohe_map.copy()\n",
    "    plot_X[feature_imp_all.columns] = np.float64(feature_imp_all.values)\n",
    "    plot_X.sort_values(by=[\"mean_feature_imp\"], ascending=False, inplace=True)\n",
    "\n",
    "    # Select top n features if specified\n",
    "    if n_features != 'all':\n",
    "        plot_X = plot_X.head(n_features)\n",
    "\n",
    "    # Prepare DataFrame for export\n",
    "    export_df = plot_X.reset_index()\n",
    "    export_df = export_df[['column_name', 'source', 'name_print', 'mean_feature_imp'] +\n",
    "                          [col for col in export_df.columns if col.startswith('model_')]]\n",
    "    export_df.columns = ['Feature', 'Source', 'Print Name', 'Mean Importance'] + \\\n",
    "                        [f'Model {i+1} Importance' for i in range(len(pl.master_RFC.models))]\n",
    "\n",
    "    # Set output path\n",
    "    if output_path is None:\n",
    "        output_path = os.path.join(pl.user_input.fig_path, f\"Feature_Importance_{pl.user_input.col_subset}_{pl.user_input.row_subset}.xlsx\")\n",
    "\n",
    "    # Export to Excel\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        export_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "\n",
    "        # Access the workbook and the worksheet\n",
    "        workbook = writer.book\n",
    "        worksheet = workbook['Feature Importance']\n",
    "\n",
    "        # Set column widths\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = [cell for cell in column]\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            worksheet.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "\n",
    "    print(f\"Feature importance data exported to: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import * #Load our package with classes pipeline, models, pp (preprocessing), plot, and more\n",
    "path= userpath(os.environ.get(\"USER\", os.environ.get(\"USERNAME\")), project=\"hcc\") # Choose your own project here, only works if you added specific project in user_settings.json\n",
    "pl=load_Pipeline(path + \"/Models/Pipelines/RFC/Pipeline_HCC_all_Model_C_RFC.joblib\") #Change for pipeline you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_feature_importance_to_excel(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Single Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(pl.trained_model.models[0][0].estimator.estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFC_Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
